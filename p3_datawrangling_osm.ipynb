{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset used:\n",
    "\n",
    "[Munich Germany](https://mapzen.com/data/metro-extracts/metro/munich_germany/) from OpenStreetMap.  \n",
    "[Download(OSMXML 39MB)](https://s3.amazonaws.com/metro-extracts.mapzen.com/munich_germany.osm.bz2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!curl https://s3.amazonaws.com/metro-extracts.mapzen.com/munich_germany.osm.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "将下载文件解压后命名为\"munich_germany.osm\"。解压后文件大小为481MB，为了简便测试，使用以下代码来生成小样本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sampling\n",
    "# 生成10分之一的测试数据。\n",
    "K10 = sampling.writeSample(\"munich_germany\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行代码，生成大小约为50MB的样本数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!du -sh munich_germany_k10.osm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更新：\n",
    "根据审阅导师的要求：\n",
    "<i>“请尝试将这两个代码文件结合在一起，实现“审阅->清理数据->shape_element->保存为json”一系列的功能。”</i>\n",
    "\n",
    "将以下的脚本合并到osmData.py文件中。主要逻辑不变，详情请阅读代码注释。\n",
    "\n",
    "运行：\n",
    "> ~ python osmData.py\n",
    "\n",
    "即可生成文件 munich_germany_k10.osm.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 审核数据 audit.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在审核osm数据时第一个遇到的问题是德语的特殊字符,例如 ä, ü，ß 等不能被python很好的解析，所以在源代码中作以下处理：\n",
    "1. 在第一或二行加入编码声明 [详情](https://www.python.org/peps/pep-0263.html)\n",
    "```python\n",
    "#coding:utf-8\n",
    "```\n",
    "2. 在打开文件时添加编码参数\n",
    "```python\n",
    "codecs.open(osmfile, mode='r', encoding='utf-8')\n",
    "```\n",
    "3. 设置python默认编码环境\n",
    "```python\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 审核街道名称\n",
    "在使用audit.py对样本进行审核后，发现由于德语的特殊性，仅简单的对街道名的词尾进行分类已不适用。例如，很多德语街道（strasse）名才取连写的方式：\n",
    "\n",
    "Rosen<span style=\"color:blue\">straße</span> （玫瑰街）\n",
    "\n",
    "\n",
    "而非：\n",
    "Rosen <span style=\"color:blue\">straße</span> （玫瑰 街）\n",
    "\n",
    "但同时也存在以下几种形式：\n",
    "\n",
    "abc<span style=\"color:blue\">straße</span>\n",
    "\n",
    "abc-<span style=\"color:blue\">straße</span>\n",
    "\n",
    "abc <span style=\"color:blue\">straße</span>\n",
    "\n",
    "考虑到针对不同的语言有不同的分词的方法，而我们的重点是数据审核和清理，这里只采用以下正则表达式：\n",
    "\n",
    "```\n",
    "street_type_re = re.compile(\n",
    "    ur'(\\s|-)?(straße|weg|ring|platz|allee|bogen|gasse|brücke|hof|berg|eck)$',\n",
    "    re.IGNORECASE | re.UNICODE) \n",
    "```\n",
    "*(我花了较长时间来使得以上的re有match，主要是在python2中，不仅compile方法需要有额外的re.UNICODE flag，还必须将string const前标注ur来转译成\"unicode string\")*\n",
    "\n",
    "在德语中除了straße（街）以外，还有weg（道），ring（环），platz（广场），allee（大道），gasse（通道），brücke（桥），hof（庄）等等。这些多次出现的词尾是经过了多次运行audit.py后得到的印象，这里将它们都加入到正则表达式的预期街道名中。\n",
    "\n",
    "在除去了以上的街道名词尾后，结果中还包涵了以下一类以“介词”开头或结尾的街道名，大多数是在POI附近的街道名，表示“在”什么附近，“靠近”某某等等，比如：\n",
    "```\n",
    "Am Krautgarten (在。。。）\n",
    "Im Wismat (靠。。。)\n",
    "Zu Maria-Eich (至。。。)\n",
    "Zur Allacher\n",
    "```\n",
    "*(在德语中介词需要根据之后的名词属性变格，比如“至。。。”（英文 to)可能有\"zu\", \"zum\", \"zur\"等多种形式)*\n",
    "\n",
    "还有针对地貌或者属性相关的街道名，例如：\n",
    "```\n",
    "Pratalinsel (。。。岛）\n",
    "Englishgarten (。。。花园）\n",
    "Rindermarkt (。。。市场)\n",
    "```\n",
    "\n",
    "在观察这些街道名之后，我将他们都加入了通过审核的字典中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据清理\n",
    "在多次调整audit.py的预期街道名之后，通过第三方地图服务（在maps.google.de）验证余下的可怀疑街道名，例如：\n",
    "```\n",
    "<node changeset=\"22627081\" id=\"2888062656\" lat=\"48.0928659\" lon=\"11.5542587\" timestamp=\"2014-05-29T20:37:14Z\" uid=\"78613\" user=\"heilbron\" version=\"1\">\n",
    "                <tag k=\"addr:city\" v=\"München\" />\n",
    "                <tag k=\"addr:street\" v=\"Über der Klause\" />\n",
    "                <tag k=\"addr:country\" v=\"DE\" />\n",
    "                <tag k=\"addr:housenumber\" v=\"4a\" />\n",
    "</node>\n",
    "```\n",
    "\n",
    "这条街道名称为\"Über der Klause\"，直译为\"经过某路的路\"，一般在道路名中使用介词\"Über\"很少见，我猜测可能是有人将description误录入了街道名，在非osm的地图服务上搜索此街道，却真的存在这样的一条街名。\n",
    "![Über der Klause](ueb.png)\n",
    "\n",
    "当然，这并不能完全证实这个名字，如果地图服务商本身用的就是osm的数据的话。这里不作讨论。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在实际项目中，我还查验了其他几个无法分类的街道名，但结果都是事实存在的，可以看出，至少，这个小样本所代表的慕尼黑附近的街道名数据是比较可靠的。\n",
    "\n",
    "### 使用prepareDB.py\n",
    "\n",
    "这个脚本主要有两个功能：\n",
    "\n",
    "1. 提取\"node\"和\"way\"的相关属性，组织层级的地址address，坐标pos及相应的键值对 &rarr; shape_element()\n",
    "2. 以json格式保存到文件，以便导入至数据库 &rarr; process_map()\n",
    "\n",
    "\n",
    "针对样本数据运行python prepareDB.py后得到:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fileutils package is required\n",
    "!du -sh munich_germany_k10.osm.json && head -n20 munich_germany_k10.osm.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import json into mongo db\n",
    "# mongo shell is required, tested version v3.2.11\n",
    "!mongoimport --db=p3 --collection=munichK10 --type=json --drop munich_germany_k10.osm.json\n",
    "\n",
    "# expected output\n",
    "# 2017-07-25T12:26:37.089+0200\tconnected to: localhost\n",
    "# 2017-07-25T12:26:37.089+0200\tdropping: p3.munichK10\n",
    "# 2017-07-25T12:26:40.088+0200\t[###########.............] p3.munichK10\t31.5MB/64.5MB (48.8%)\n",
    "# 2017-07-25T12:26:42.790+0200\t[########################] p3.munichK10\t64.5MB/64.5MB (100.0%)\n",
    "# 2017-07-25T12:26:42.790+0200\timported 238481 documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 删除冗余数据\n",
    "在初步浏览数据后，发现有一部分数据的经纬度都为[0,0]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "> db.munichK10.find({'pos':[0,0]}).count()\n",
    "\n",
    "# 39431"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑到我们下载的是慕尼黑周边的区域，坐标不可能是[0,0]，遂从数据集中删除这个数据项："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "> db.munichK10.update(\n",
    "    {'pos':[0,0]},\n",
    "    {$unset:{pos:\"\"}},\n",
    "    {multi:true})\n",
    "\n",
    "# WriteResult({ \"nMatched\" : 39431, \"nUpserted\" : 0, \"nModified\" : 39430 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据概览\n",
    "注：以下输出都是基于1/10的小数据。在下一节中使用的是400mb左右的‘大’数据，在我的Intel(R) Xeon(R) CPU E5620@2.40GHz机子上，针对munich_germany.osm进行一次preparDB.py的运算大约需要30分钟，将会生成大约1600万条记录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# within Mongo shell\n",
    "# remove suffix '10' to explore the complete collection\n",
    "> use p3\n",
    "> m10=p3.munichK10\n",
    "> m10.findOne()\n",
    "\n",
    "# {\n",
    "# \t\"_id\" : ObjectId(\"59771d9fd3887b94873fa162\"),\n",
    "# \t\"pos\" : [\n",
    "# \t\t48.1963217,\n",
    "# \t\t11.3599471\n",
    "# \t],\n",
    "# \t\"type\" : \"node\",\n",
    "# \t\"id\" : \"128218\",\n",
    "# \t\"created\" : {\n",
    "# \t\t\"changeset\" : \"13511613\",\n",
    "# \t\t\"user\" : \"burt13de\",\n",
    "# \t\t\"version\" : \"6\",\n",
    "# \t\t\"uid\" : \"247670\",\n",
    "# \t\t\"timestamp\" : \"2012-10-15T20:53:25Z\"\n",
    "# \t}\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of documents\n",
    "> m10.find().count()\n",
    "\n",
    "# 24841"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of nodes\n",
    "> m10.find({'type':'node'}).count()\n",
    "\n",
    "# 199050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of ways\n",
    "> m10.find({'type':'way'}).count()\n",
    "\n",
    "# 39431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unique user\n",
    "> m10.distinct(\"created.user\").length\n",
    "\n",
    "# 1935"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# top 3 most contributed users\n",
    "> m10.aggregate([\n",
    "    {$group:{'_id':'$created.user', 'count':{$sum:1}}},\n",
    "    {$sort:{'count':-1}},\n",
    "    {$limit:3}\n",
    "])\n",
    "\n",
    "# { \"_id\" : \"ToniE\", \"count\" : 27018 }\n",
    "# { \"_id\" : \"BeKri\", \"count\" : 23354 }\n",
    "# { \"_id\" : \"rolandg\", \"count\" : 18677 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of users who posted only 1, 2 or 3 times.\n",
    "> m10.aggregate([\n",
    "    {$group:{'_id':'$created.user', 'count':{$sum:1}}},\n",
    "    {$group:{'_id':'$count', user_count:{$sum:1}}},\n",
    "    {$sort:{'user_count':-1}},\n",
    "    {$limit:3}\n",
    "])\n",
    "\n",
    "# { \"_id\" : 1, \"user_count\" : 640 }\n",
    "# { \"_id\" : 2, \"user_count\" : 222 }\n",
    "# { \"_id\" : 3, \"user_count\" : 109 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# top 5 amenities\n",
    "> m10.aggregate([\n",
    "    {$match:{'amenity':{'$exists':1}}},\n",
    "    {$group:{'_id':'$amenity', 'count':{$sum:1}}},\n",
    "    {$sort:{'count':-1}},\n",
    "    {$limit:5},\n",
    "])\n",
    "\n",
    "# { \"_id\" : \"bench\", \"count\" : 552 }\n",
    "# { \"_id\" : \"parking\", \"count\" : 538 }\n",
    "# { \"_id\" : \"vending_machine\", \"count\" : 256 }\n",
    "# { \"_id\" : \"shelter\", \"count\" : 187 }\n",
    "# { \"_id\" : \"waste_basket\", \"count\" : 180 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# top 10 cuisine art of restaurants\n",
    "> m10.aggregate([\n",
    "    {$match:{\n",
    "        'amenity':{$exists:1},\n",
    "        'amenity':'restaurant',\n",
    "        'cuisine':{$exists:1}}},\n",
    "    {$group:{'_id':'$cuisine', 'count':{'$sum':1}}},\n",
    "    {$sort:{'count':-1}},\n",
    "    {$limit: 10}\n",
    "])\n",
    "\n",
    "# { \"_id\" : \"italian\", \"count\" : 37 }\n",
    "# { \"_id\" : \"regional\", \"count\" : 11 }\n",
    "# { \"_id\" : \"asian\", \"count\" : 8 }\n",
    "# { \"_id\" : \"vietnamese\", \"count\" : 8 }\n",
    "# { \"_id\" : \"indian\", \"count\" : 8 }\n",
    "# { \"_id\" : \"thai\", \"count\" : 5 }\n",
    "# { \"_id\" : \"chinese\", \"count\" : 5 }\n",
    "# { \"_id\" : \"bavarian\", \"count\" : 4 }\n",
    "# { \"_id\" : \"greek\", \"count\" : 4 }\n",
    "# { \"_id\" : \"german\", \"count\" : 4 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 探索数据\n",
    "为了能对字符串进行搜索，对正个数据集的‘text’建立索引："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "> m = db.munich\n",
    "> m.createIndex( {\"$**\":\"text\"})\n",
    "\n",
    "#\t\"createdCollectionAutomatically\" : false,\n",
    "#\t\"numIndexesBefore\" : 2,\n",
    "#\t\"numIndexesAfter\" : 2,\n",
    "#\t\"note\" : \"all indexes already exist\",\n",
    "#\t\"ok\" : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how many cinema we have\n",
    "> m.find({ $text:{$search:'cinema'}}).count()\n",
    "\n",
    "# 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in last several years, which part of the munich has the most map data collected?\n",
    "> m.aggregate([\n",
    "    {$match:{'address.postcode':{$exists:1}}},\n",
    "    {$group:{'_id':{\n",
    "        year: {$year: '$created.isots'},\n",
    "        plz: '$address.postcode'\n",
    "        },\n",
    "        count: {$sum:1}}},\n",
    "    {$sort:{'count':-1}},\n",
    "    {$limit: 5}\n",
    "])\n",
    "\n",
    "# { \"_id\" : { \"year\" : 2013, \"plz\" : \"82194\" }, \"count\" : 5280 }\n",
    "# { \"_id\" : { \"year\" : 2014, \"plz\" : \"81827\" }, \"count\" : 3788 }\n",
    "# { \"_id\" : { \"year\" : 2014, \"plz\" : \"81825\" }, \"count\" : 3306 }\n",
    "# { \"_id\" : { \"year\" : 2014, \"plz\" : \"81739\" }, \"count\" : 2786 }\n",
    "# { \"_id\" : { \"year\" : 2014, \"plz\" : \"81929\" }, \"count\" : 2342 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我没有想到的是慕尼黑西北边的小镇[Gröbenzell](https://zh.wikipedia.org/wiki/%E6%A0%BC%E5%8B%92%E6%9C%AC%E9%87%87%E5%B0%94)(postcode 82194)在近几年收录了比主城区更多的地理信息记录。![Gröbenzell](gbz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题二\n",
    "从Open street map生成的json文件导入mongodb后的“timestamp”格式为string类，并非mongodb的[Date](https://docs.mongodb.com/manual/reference/operator/query/type/#document-type-available-types) type。当我希望根据时间来分组(group)时，会有如下报错：\n",
    "```mongodb\n",
    "command failed: {\n",
    "        \"errmsg\" : \"exception: can't convert from BSON type EOO to Date\",\n",
    "        \"code\" : 16006,\n",
    "        \"ok\" : 0 } : aggregate failed\n",
    "```\n",
    "[解决方法](https://stackoverflow.com/questions/28415995/exception-cant-convert-from-bson-type-eoo-to-date)：通过强制转换，并新增加一项\"isots\"来处理这个时间戳：\n",
    "```mongodb\n",
    "db.munich.find({'created.timestamp': {$not: {$type: 9}}}).forEach(function(d) { \n",
    "    d.created.isots = new Date(d.created.timestamp);\n",
    "    db.munich.save(d);\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 问题一\n",
    "在使用mongodb时，有一部分查询会给出报错信息：\n",
    "\n",
    "> uncaught exception: can't have . in field names [fields.footway]\n",
    "\n",
    "这是因为在prepareDB.py中，我将所有tag的属性k，v值，直接添加到node或way的{k:v}字典中，而原本作为属性k的值是可能包含\".\"符号的。例如：\n",
    "```xml\n",
    "<tag k=\"footway:right.sloped_curb.end\" v=\"0.02\" />\n",
    "```\n",
    "将被转换为：\n",
    "```json\n",
    "{\n",
    "    \"footway:right.sloped_curb.end\": \"0.02\"\n",
    "}\n",
    "```\n",
    "\n",
    "而mongodb的fieldname不支持\".\"。一个[解决方法](https://stackoverflow.com/questions/8429318/how-to-use-dot-in-field-name)是将\".\"符号转换成unicode \"\\uff0e\"。但我对这类tag的信息并不特别感兴趣，这里就省直接略掉：\n",
    "```python\n",
    "if '.' not in key:\n",
    "    node[key] = value \n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更新：\n",
    "# 关于数据集的其他想法\n",
    "由于open stree map是开放格式的，就会带来对数据验证的困难。下图是\n",
    "![db_schema](OSM_DB_Schema_2016-12-13.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结\n",
    "在完成这个项目时，我感觉到数据清理的难点有以下几个方面：\n",
    "\n",
    "* 数据格式的多样及不确定使得程序不能很好的执行，这里osm xml其实并没有一个确定的schema或dtd用来审核数据，这也许是“开放”所带来的一个问题。\n",
    "* 数据的编码及储存格式会带来问题。\n",
    "* 用不同的自然语言记录的信息在处理上会有不同。\n",
    "* 解析数据会耗费大量内存空间，尽管使用了‘流’式的解析xml的方法，仍然需要很多时间。这可能与python语言的运行效率有关。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
